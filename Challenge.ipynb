{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa022aed-0e22-47c4-b41b-0669ed1e3a30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from datetime import date, datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sqlalchemy import MetaData, func, and_, distinct, tuple_\n",
    "from db import init_db, get_db\n",
    "from orm import Base\n",
    "from orm import Crime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892de23b-92ac-4f0c-a872-85f2385f3ba4",
   "metadata": {},
   "source": [
    "# For simplicity we'll create a local SQLite database for our analysis\n",
    "- You can use something like DBeaver to connect to and query your database with a SQL editor, by pointing the connection to the file that will be created in your cwd\n",
    "- You'll need to delete this file when you edit/modify your ORM, so the table can be re-created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d901ed-4fb8-466f-aaae-a20744c65c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_kwargs = {\n",
    "    'echo': False # can turn this off to ignore all the background DB noise\n",
    "}\n",
    "init_db(**conn_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d447ad-57c4-4312-ac89-a1eadf465d6e",
   "metadata": {},
   "source": [
    "### <font color=\"red\"> THIS WILL NOT WORK UNTIL YOU FIX THE orm.py FILE! See Below</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a162d3ec-5628-464c-8623-27504c1ec0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = get_db()\n",
    "Base.metadata.create_all(bind=db.engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884d3ddb-7e55-4f1f-8bdd-4c516ee6ecd5",
   "metadata": {},
   "source": [
    "## Some notes on getting this to work\n",
    "- We needed to add the '--user' flag to the command to create the kernel in our jupyter notebooks from the venv we created for this project. <br>\n",
    "Our command: python3 -m ipykernel install --user --name pairin_kernel --display-name \"PAIRIN_Kernel\"\n",
    "- next, orm would not import until data types were set in the orm.py file for the Crime class. <br>\n",
    "We used 'String' types for everything on the first pass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84714c49-7212-4058-ad90-75985475b203",
   "metadata": {},
   "source": [
    "## Let's start with our ORM\n",
    "- what exploratory data analysis can we do on this to figure out what kind of data we have and what SQL data types and sizes we should use to store the data?  Include whatever you might do to inspect the data and some notes on your thoughts\n",
    "* we could look at the unique values for each column in the database.\n",
    "- we need to add a \"created_at\" column to the dataset\n",
    "* For Reference: https://stackoverflow.com/questions/7300948/add-column-to-sqlalchemy-table .  It sounds like there a many ways to do this in sqlalchemy, but no method seems to be the accepted or recommended method to do this. In this case, I will try adding the column to the dataframe\n",
    "- if we had too many rows to open the file in memory, what would you do?\n",
    "* Generally, I woulld follow the steps used in this example. Work with a large, but usable, chunk of the data and develop our methods using this subsample of data. Once I had ironed out most of the kinks with this data set, I would then probably move to spark and/or databricks and use a scalable system to work with the whole data set. If I can't get spark to work, then I would look at other methods for streaming data through my database builder. If that doesn't work, then I would probably just iterate over the dataset subsample by subsample to get the database built.\n",
    "- if you were certain about the data types in advance, how could you use that knowledge while loading the file?\n",
    "* it would make building the orm.py file easier. Also, we can use the data types to set data types in the pd.readcsv command. This could reduce overhead on the process and allow us to work with larger subsets of the entire data set.\n",
    "- once you know what the pandas data types should be, how do you convert the columns to the correct types before importing?\n",
    "* https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html - dtypeType name or dict of column -> type, optional Data type for data or columns. E.g. {‘a’: np.float64, ‘b’: np.int32, ‘c’: ‘Int64’} Use str or object together with suitable na_values settings to preserve and not interpret dtype. If converters are specified, they will be applied INSTEAD of dtype conversion.\n",
    "- re: ORM, don't worry about configuring indexes, keys or things like this, but feel free to describe what columns you might consider for indexing based on how you might expect to use the data and why?\n",
    "* It looks like lsoa_code could be used as an index for the main table.\n",
    "- is there a compelling case to de-normalize and create multiple tables with foreign keys?  Don't worry about implemeting that, just walk me through your thoughts?\n",
    "* It looks like borough could be denormalized to save space. Also, it already looks like this table might be from a set of de-normalized tables as there should be other tables with more details on these events in a data architecture. This table is already pretty small, so there may not be too much value in de-normalizing this data set, unless space is at a premium or the data set is unmanageably large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad4cf5-82e5-42f6-b99a-8004c7cc31a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('data')\n",
    "file_name = 'london_crime_by_lsoa.csv'\n",
    "\n",
    "# we'll take just the first million rows to speed things up\n",
    "df = pd.read_csv(data_path/file_name, sep=',', dtype='string', nrows=1_000_000)\n",
    "print(f'We have {len(df)} records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3368f4c3-9f27-4ce8-873f-9a89dc3a2cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56bb925-6e96-4c8b-8cf4-f4ff93980014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e09a46-9236-4d7e-b6e5-8047724853b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda42b80-5ef2-4a4e-b3cb-f5b47fabe288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['value'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd60241-b712-44c0-923a-e1dd812ae7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.lsoa_code.str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eae1b33-ff88-4ab9-acff-056979d0fae5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.borough.str.len().max()\n",
    "\n",
    "print('max string length of columns in database')\n",
    "print(df.lsoa_code.str.len().max(), 'lsoa_code')\n",
    "print(df.borough.str.len().max(), 'borough')\n",
    "print(df.major_category.str.len().max(), 'major_category')\n",
    "print(df.minor_category.str.len().max(), 'minor_category')\n",
    "print(df.value.str.len().max(), 'value')\n",
    "print('')\n",
    "print('Looks like String lengths of 50 should be sufficient.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20589fe0-c93d-4dfd-9ea0-4e18c1e226ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a created_at column with current timestamp, or implement your orm to do it for you\n",
    "# df.columns\n",
    "df['created_at'] = datetime.now()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999ff271-83c5-4688-a77d-7f4849e8f502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we probably need to convert some pandas data types away from string before importing?\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html\n",
    "# df.dtypes\n",
    "df.value = pd.to_numeric(df.value, downcast='integer')\n",
    "df.year = pd.to_numeric(df.year, downcast='integer')\n",
    "df.month = pd.to_numeric(df.month, downcast='integer')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee01bf0-92da-4ffe-bd3f-d0a5f4ec7393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update your ORM file to add in appropriate column types\n",
    "# check orm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09389f32-d639-467f-bc41-0cdab5c0a82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# once you have your data types sorted and ORM implemented, you can use this to import the data\n",
    "def bulk_load(df: pd.DataFrame) -> None:\n",
    "    chunk_size = 100_000\n",
    "    for idx in range(0, len(df), chunk_size):        \n",
    "        print(f'Inserting chunk {idx}:{idx+chunk_size}')\n",
    "\n",
    "        with get_db().session_scope() as session:\n",
    "\n",
    "            cols = [\n",
    "                'lsoa_code', 'borough', 'major_category', 'minor_category',\n",
    "                'value', 'year', 'month', 'created_at'\n",
    "            ]         \n",
    "\n",
    "            records = df[idx:idx+chunk_size][cols].astype(object).to_dict(orient='records')\n",
    "            session.bulk_insert_mappings(Crime, records, render_nulls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e45f65-689a-4353-bd37-acde44507990",
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_load(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8610bb1c-f0a2-4ddc-92bf-26b11d017843",
   "metadata": {},
   "source": [
    "## Questions to answer, for now ignore the database, and show me your pandas code for the following\n",
    "- Overall, which borough had the most crime?\n",
    "- How many major categories of crime are there?\n",
    "- How many distinct combinations of (major_category, minor_category) are there?\n",
    "- What were the top 5 major categories of crime?\n",
    "- What was the count of major cat Burglary for Croydon in December 2014?\n",
    "- Show me total crime counts per year\n",
    "- Which borough had to biggest increase in overall crime from 2008 vs 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e14d71-0d9c-4e55-b670-e715770d5139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c146e7-67d4-4c7b-ad97-8611948a82c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall, which borough had the most crime?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641501df-c865-4ec9-928e-7755bf04ebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html\n",
    "borough_crime = pd.pivot_table(df, values='value', index=['borough'], aggfunc=np.sum)\n",
    "print(borough_crime.sort_values(by=['value'], ascending=False))\n",
    "print('')\n",
    "print('Westminster is the borough with the most crime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a771da-2e23-41d8-8c74-6920b411830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many major categories of crime are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f9bcf5-76d8-4084-a32e-44f3cefe9ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df['major_category'].unique())\n",
    "print('')\n",
    "print('there are 9 major categories of crime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0011c330-8d40-4122-a7c1-d778bbc88939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many distinct combinations of (major_category, minor_category) are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06d6d98-72b4-42e2-9ac6-7518aa39ce08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.groupby(['major_category', 'minor_category']).size())\n",
    "print('')\n",
    "# print(df.drop_duplicates(subset=['major_category', 'minor_category']))\n",
    "print('there are 32 distinct combinations of (major_category, minor_category)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c80aaa3-74a0-4f72-81bf-76277d3ea4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What were the top 5 major categories of crime?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aca875-db53-486e-9eb3-a68b0e72d932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_major = pd.pivot_table(df, values='value', index=['major_category'], aggfunc=np.sum)\n",
    "print(top_major.sort_values(by=['value'], ascending=False).head(5))\n",
    "print('')\n",
    "print('the above are the top 5 major cateroies of crime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c585ae8-c53d-49cd-9fce-aad1056a50ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was the count of Burglary for Croydon in 2014?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a444f6f-e7fe-42d1-b3f6-511604ef5cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html\n",
    "answer = df.loc[((df.major_category == 'Burglary') & (df.borough == 'Croydon') & (df.year == 2014))].shape[0]\n",
    "print('the count of Burglary for Croydon in 2014 is', answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48be5cc-7800-42e9-89a6-9be98c290822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show me total crime counts per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589dd69b-6723-4a4e-9640-c1dfee1fb427",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "crime_year = pd.pivot_table(df, values='value', index=['year'], aggfunc=np.sum)\n",
    "crime_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6384125-1791-457d-99af-b28d6d9ec4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which borough had to biggest increase in crime from 2008 vs 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa74180-5775-4e32-a576-656154fa9b89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "crime_borough_year = pd.pivot_table(df, values='value', index=['borough', 'year'], aggfunc=np.sum)\n",
    "crime_borough_2008 = pd.pivot_table(df.loc[df.year == 2008], values='value', index=['borough'], aggfunc=np.sum) \n",
    "crime_borough_2016 = pd.pivot_table(df.loc[df.year == 2016], values='value', index=['borough'], aggfunc=np.sum)\n",
    "crime_borough_group = df.loc[((df.year == 2008) | (df.year == 2016))].groupby(['borough', 'year']).agg({'value' : 'sum'})\n",
    "# crime_borough_group\n",
    "take_diff = lambda s1, s2: s1-s2\n",
    "crime_borough_diff = crime_borough_2016.combine(crime_borough_2008, take_diff)\n",
    "crime_borough_diff.sort_values(by='value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012068d2-be84-4a1a-bf77-7fa1c3dd8ad0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "crime_borough_west = df.loc[(((df.year == 2008) | (df.year == 2016)) & (df.borough == 'Westminster'))].groupby(['borough', 'year']).agg({'value' : 'sum'})\n",
    "crime_borough_west"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed165bd8-8d7c-4394-9c18-748a66b19663",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Which borough had to biggest increase in crime from 2008 vs 2016?')\n",
    "print('')\n",
    "print('answer: Westminster')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f26efe-192a-4743-807e-b799e70a4d44",
   "metadata": {},
   "source": [
    "## OK, same questions to answer, but now let's pretend our dataset is too big for memory, so we need to leverage the database... If you're not familiar with SQLAlchemy, that's ok, just provide the raw SQL to accomplish the task.   You can connect to your database using something like DBeaver https://dbeaver.io/download/ by just pointing it at the crime.db file in you cwd\n",
    "- Overall, which borough had the most crime?\n",
    "- How many major categories of crime are there?\n",
    "- How many distinct combinations of (major_category, minor_category) are there?\n",
    "- What were the top 5 major categories of crime?\n",
    "- What was the count of major category Burglary for Croydon in December 2014?\n",
    "- Show me total crime counts per year\n",
    "- Which borough had to biggest increase in overall crime from 2008 vs 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e916998c-8c53-40bf-874e-2fc20b5daba5",
   "metadata": {},
   "source": [
    "## For the first one, I'll show the SQL / SQLAlchemy\n",
    "\n",
    "- Overall, which borough had the most crime?\n",
    "\n",
    "Raw SQL\n",
    "```SQL\n",
    "select \n",
    "\tborough, sum(value) as total_crimes\n",
    "from\n",
    "\tcrimes\n",
    "group by\n",
    "\tborough\n",
    "order by\n",
    "\tsum(value) desc\n",
    "limit 1\n",
    "```\n",
    "\n",
    "Python SQLAlchemy\n",
    "```python\n",
    "with get_db().session_scope() as session:\n",
    "\n",
    "    qry = session.query(\n",
    "                Crime.borough, func.sum(Crime.value)) \\\n",
    "            .group_by(Crime.borough) \\\n",
    "            .order_by(func.sum(Crime.value).desc()) \\\n",
    "            .limit(1)\n",
    "    \n",
    "    print(qry)\n",
    "    \n",
    "    df =  pd.read_sql_query(qry.statement, session.bind)\n",
    "        \n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68c752a-f83d-4fdf-99b1-7a88fe016458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many major categories of crime are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9599275d-9c42-4432-9081-945130e61d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many distinct combinations of (major_category, minor_category) are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ad7bf8-c0d8-4883-a7e5-f6a7d605aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What were the top 5 major categories of crime?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e78a32-13d4-40ca-8207-5b14178acd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was the count of Burglary for Croydon in 2014?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a35531-4737-4e64-b8ea-b7d48130bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show me total crime counts per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9e58e7-d2a9-42db-b852-37d7a4da67df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which borough had to biggest increase in sum total crime from 2008 vs 2016\n",
    "# this one can be tricky in SQLAlchemy, so raw SQL would suffice if you want"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PAIRIN_Kernel",
   "language": "python",
   "name": "pairin_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
